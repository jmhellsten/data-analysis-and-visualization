{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea19a7c204a17199",
   "metadata": {},
   "source": [
    "# Pandas Library 2\n",
    "\n",
    "These assignments are related to **Pandas** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09cdd56904dbe75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:33:40.517567Z",
     "start_time": "2025-02-05T17:33:40.495567Z"
    }
   },
   "outputs": [],
   "source": [
    "student_name = 'Juha-Matti Hellsten'\n",
    "student_id = 'AG7990'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25805b",
   "metadata": {},
   "source": [
    "## Handling NaN values\n",
    "\n",
    "The goal of this assignment is to handle NaN (Not a Number) values within a `DataFrame`.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `read_last_rows()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variables `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`.\n",
    "* Keep all rows that have at most **two** `NaN` columns. In other words, filter out all rows that have at least three `NaN` values.\n",
    "* Return the last five (5) rows of the `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9089da21-34bb-48ec-9708-895624ba8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sepal length  Sepal width  Petal length  Petal width         Species\n",
      "145           6.7          NaN           NaN          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "149           NaN          3.0           5.1          NaN  Iris-virginica\n",
      "151           5.9          3.0           NaN          NaN  Iris-virginica\n",
      "     Sepal length  Sepal width  Petal length  Petal width         Species\n",
      "145           6.7          NaN           NaN          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "149           NaN          3.0           5.1          NaN  Iris-virginica\n",
      "151           5.9          3.0           NaN          NaN  Iris-virginica\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "correct_03_01 = pd.DataFrame({'Sepal length': {145: 6.7, 146: 6.3, 147: 6.5, 149: np.nan, 151: 5.9},\n",
    "                              'Sepal width': {145: np.nan, 146: 2.5, 147: 3.0, 149: 3.0, 151: 3.0},\n",
    "                              'Petal length': {145: np.nan, 146: 5.0, 147: 5.2, 149: 5.1, 151: np.nan},\n",
    "                              'Petal width': {145: 2.3, 146: 1.9, 147: 2.0, 149: np.nan, 151: np.nan},\n",
    "                              'Species': {145: 'Iris-virginica', 146: 'Iris-virginica', 147: 'Iris-virginica',\n",
    "                                          149: 'Iris-virginica', 151: 'Iris-virginica'}})\n",
    "\n",
    "\n",
    "def read_last_rows(url_src, n_last):\n",
    "    df = pd.read_csv(url_src, header=None)\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "    for col in df.columns[:-1]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    nan_counts = df.isna().sum(axis=1)\n",
    "    filtered_df = df[nan_counts <= 2]\n",
    "    result = filtered_df.tail(n_last)   \n",
    "    \n",
    "    filtered_df = df[nan_counts <= 2]\n",
    "    result = filtered_df.tail(n_last)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# The Test Program includes automatic checking of the answer.\n",
    "url_src = r\"C:\\Users\\jmhel\\OneDrive\\Työpöytä\\JAMK\\DA & Visualization\\iris_1.csv\"\n",
    "res = read_last_rows(url_src, 5)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_01, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22704b2d",
   "metadata": {},
   "source": [
    "## Calculating values\n",
    "\n",
    "The primary goal of this assignment is reading iris data from a CSV file, processing data, and conducting specific analyses.\n",
    "Calculate the share of irises that are filtered by the given petal width or length as a percentage of all categories of iris flowers.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `iris_count_rows()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`.\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`. And then convert all `NaN` values to zeroes but don't remove them.\n",
    "* Count how many irises you find with a `Petal width` less than or equal to `0.2` and greater than `0.0`.\n",
    "* Count how many irises you find where the `Petal length` is greater than or equal to `5.0` but less than or equal to `5.2`.\n",
    "* Then calculate their share of all iris flowers (so total percentages of all flowers).\n",
    "* Create the following indexes for `Series`: `['found petal width', 'found petal length', 'found petal width %', 'found petal length %']` and add the values calculated for them.\n",
    "* Return the resulting `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e7bbe9-18e2-4e31-8b3b-0829c7f28b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found petal width       34.00\n",
      "found petal length      13.00\n",
      "found petal width %     22.37\n",
      "found petal length %     8.55\n",
      "dtype: float64\n",
      "found petal width       34.00\n",
      "found petal length      13.00\n",
      "found petal width %     22.37\n",
      "found petal length %     8.55\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "correct_03_02 = pd.Series(\n",
    "    {'found petal width': 34, 'found petal length': 13, 'found petal width %': 22.37, 'found petal length %': 8.55}\n",
    ")\n",
    "\n",
    "\n",
    "def iris_count_rows(url):\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "    for col in df.columns[:-1]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    petal_width_count = ((df[\"Petal width\"] <= 0.2) & (df[\"Petal width\"] > 0.0)).sum()\n",
    "    petal_length_count = ((df[\"Petal length\"] >= 5.0) & (df[\"Petal length\"] <= 5.2)).sum()\n",
    "    \n",
    "    total_irises = len(df)\n",
    "    petal_width_percentage = round((petal_width_count / total_irises) * 100, 2)\n",
    "    petal_length_percentage = round((petal_length_count / total_irises) * 100, 2)\n",
    "    \n",
    "    results = pd.Series(\n",
    "        [petal_width_count, petal_length_count, petal_width_percentage, petal_length_percentage],\n",
    "        index=['found petal width', 'found petal length', 'found petal width %', 'found petal length %']\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# The Test Program includes automatic checking of the answer.\n",
    "url_src = r\"C:\\Users\\jmhel\\OneDrive\\Työpöytä\\JAMK\\DA & Visualization\\iris_1.csv\"\n",
    "res = iris_count_rows(url_src)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_series_equal(res, correct_03_02, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475f50f",
   "metadata": {},
   "source": [
    "## Grouping and Multi-indexes\n",
    "\n",
    "The primary goal of this assignment is reading iris data from a CSV file, processing the data, and calculating statistical values for specific columns.\n",
    "The assignment involves performing group-based calculations, and structuring the results in a _Multi-index_ `DataFrame`.\n",
    "\n",
    "In this assignment, you will read data from CSV file to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `calculate_stats_for_groups()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Read all columns from given file.\n",
    "* Set column names in the following order: `\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"`.\n",
    "* Convert all numeric columns to the appropriate numeric format.\n",
    "* Convert all non-numeric column values to `NaN`.\n",
    "* Filter out all rows that have at least one `NaN` values.\n",
    "* For each iris class separately, calculate the statistical values `(number of items, average, median)` for the `'Sepal length'` and `'Sepal width'` columns.\n",
    "* Return the results in the Multi-index `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba474c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:33:41.261079Z",
     "start_time": "2025-02-05T17:33:41.237825Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sepal length                Sepal width               \n",
      "                       count    mean median       count    mean median\n",
      "Species                                                               \n",
      "Iris-setosa               50  5.0060    5.0          50  3.4180    3.4\n",
      "Iris-versicolor           50  5.9360    5.9          50  2.7700    2.8\n",
      "Iris-virginica            43  6.6186    6.5          43  2.9535    3.0\n",
      "                Sepal length                Sepal width               \n",
      "                       count    mean median       count    mean median\n",
      "Species                                                               \n",
      "Iris-setosa               50  5.0060    5.0          50  3.4180    3.4\n",
      "Iris-versicolor           50  5.9360    5.9          50  2.7700    2.8\n",
      "Iris-virginica            43  6.6186    6.5          43  2.9535    3.0\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "correct_03_03 = pd.DataFrame(\n",
    "    {('Sepal length', 'count'): {'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 43},\n",
    "     ('Sepal length', 'mean'): {'Iris-setosa': 5.006, 'Iris-versicolor': 5.936, 'Iris-virginica': 6.618604651162792},\n",
    "     ('Sepal length', 'median'): {'Iris-setosa': 5.0, 'Iris-versicolor': 5.9, 'Iris-virginica': 6.5},\n",
    "     ('Sepal width', 'count'): {'Iris-setosa': 50, 'Iris-versicolor': 50, 'Iris-virginica': 43},\n",
    "     ('Sepal width', 'mean'): {'Iris-setosa': 3.418, 'Iris-versicolor': 2.77, 'Iris-virginica': 2.953488372093023},\n",
    "     ('Sepal width', 'median'): {'Iris-setosa': 3.4, 'Iris-versicolor': 2.8, 'Iris-virginica': 3.0}})\n",
    "correct_03_03.index.name = \"Species\"\n",
    "\n",
    "def calculate_stats_for_groups(url):\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df.columns = [\"Sepal length\", \"Sepal width\", \"Petal length\", \"Petal width\", \"Species\"]\n",
    "    \n",
    "\n",
    "    for col in df.columns[:-1]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "        df = df.dropna()\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    for column in ['Sepal length', 'Sepal width']:\n",
    "        count_series = df.groupby('Species')[column].count()\n",
    "        mean_series = df.groupby('Species')[column].mean()\n",
    "        median_series = df.groupby('Species')[column].median()\n",
    "        \n",
    "        result[(column, 'count')] = count_series\n",
    "        result[(column, 'mean')] = mean_series\n",
    "        result[(column, 'median')] = median_series\n",
    "    \n",
    "    result.index.name = \"Species\"\n",
    "    result.columns = pd.MultiIndex.from_tuples(result.columns)\n",
    "    \n",
    "    return result.round(4)\n",
    "\n",
    "\n",
    "# The Test Program includes automatic checking of the answer.\n",
    "url_src = r\"C:\\Users\\jmhel\\OneDrive\\Työpöytä\\JAMK\\DA & Visualization\\iris_1.csv\"\n",
    "res = calculate_stats_for_groups(url_src)\n",
    "print(res)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_03, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ebd39-4a04-488c-b2fa-4ec3c5e43ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ff7561",
   "metadata": {},
   "source": [
    "## Grouping, filtering and reading text file\n",
    "\n",
    "The primary goal of this assignment is reading data from a text file, processing the data, and conducting specific operations on the `DataFrame`.\n",
    "The assignment involves performing data manipulations, and presenting results according to specified formatting requirements.\n",
    "\n",
    "In this assignment, you will read data from text file (it's not directly in CSV format) to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `emissions_per_sector()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Save only columns `main activity sector name`, `value` and `year` in the DataFrame.\n",
    "* Rename the column `main activity sector name` to the column `sector`.\n",
    "* Remove from the DataFrame the rows where the strings `20-99 All stationary installations` or `21-99 All industrial installations (excl. combustion)` appear in any column.\n",
    "* Save in a new DataFrame all rows where `year` column *>= 2010* and *<= 2015*.\n",
    "* Calculate the total emissions by sector in the new `DataFrame`. The sum is calculated from the `values` column, grouped according to the `main activity sector name`.\n",
    "* Sort the rows of the `DataFrame` in descending order according to the column `value`.\n",
    "* Round the resulting `float` values to _two (2) decimal_ places and display the float results in a _20-column wide_ field and in _non-scientific notation_.\n",
    "* Return the first six (6) rows from the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6df223-f4e1-43c1-b059-b4ff02d37146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               value                              sector\n",
      "   16,744,275,369.00              20 Combustion of fuels\n",
      "    2,135,161,344.00 24  Production of pig iron or steel\n",
      "    1,859,208,638.00     29 Production of cement clinker\n",
      "    1,714,290,908.00         21  Refining of mineral oil\n",
      "      669,997,806.00                         10 Aviation\n",
      "      554,345,679.00     42 Production of bulk chemicals\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "correct_03_04 = \"\"\"               value                              sector\n",
    "   16,744,275,369.00              20 Combustion of fuels\n",
    "    2,135,161,344.00 24  Production of pig iron or steel\n",
    "    1,859,208,638.00     29 Production of cement clinker\n",
    "    1,714,290,908.00         21  Refining of mineral oil\n",
    "      669,997,806.00                         10 Aviation\n",
    "      554,345,679.00     42 Production of bulk chemicals\"\"\"\n",
    "\n",
    "def emissions_per_sector(url):\n",
    "    with open(url, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    headers = lines[0].strip().strip('\"').split('\\t')\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "    \n",
    "        clean_line = line.strip().strip('\"')\n",
    "        values = clean_line.split('\\t')\n",
    "        data.append(values)\n",
    "   \n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "   \n",
    "   \n",
    "    df = df[[\"main activity sector name\", \"value\", \"year\"]]\n",
    "    df.rename(columns={\"main activity sector name\": \"sector\"}, inplace=True)\n",
    "    \n",
    "    df = df[~df[\"sector\"].str.contains(\"20-99 All stationary installations|21-99 All industrial installations\", regex=True)]\n",
    "    \n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "    \n",
    "    df = df[(df[\"year\"] >= 2010) & (df[\"year\"] <= 2015)]\n",
    "    \n",
    "    grouped = df.groupby(\"sector\", as_index=False)[\"value\"].sum()\n",
    "    grouped = grouped.sort_values(by=\"value\", ascending=False)\n",
    "    \n",
    "    pd.options.display.float_format = '{:20,.2f}'.format\n",
    "    \n",
    "    return grouped[[\"value\", \"sector\"]].head(6)\n",
    "\n",
    "# The Test Program includes automatic checking of the answer.\n",
    "url_src = r\"C:\\Users\\jmhel\\OneDrive\\Työpöytä\\JAMK\\DA & Visualization\\emissions.csv\"\n",
    "res = emissions_per_sector(url_src)\n",
    "\n",
    "try:\n",
    "    print(res.to_string(index=False))\n",
    "    assert res.to_string(index=False) == correct_03_04, \"Error in result\"\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e60726",
   "metadata": {},
   "source": [
    "## Grouping, calculating, and time-based analysis\n",
    "\n",
    "The primary goal of this assignment is reading data from a text file, processing the data, and conducting specific operations on the DataFrame.\n",
    "The assignment involves reading emission data from a text file, implementing time-based analysis, and calculating various metrics related to emissions over the years.\n",
    "\n",
    "In this assignment, you will read data from text file (note that it's not directly in CSV format) to `DataFrame`.\n",
    "In this assignment, the implementation code is done in the `emissions_per_year()` function.\n",
    "\n",
    "* Read the CSV file found in the filename defined in the test program variable `url_src`.\n",
    "* Save the following columns `country_code`, `main activity sector name`, `value` and `year` in the `DataFrame`.\n",
    "* Rename the column `main activity sector name` to the `sector`.\n",
    "* Remove from the DataFrame the rows where the strings `20-99 All stationary installations` or `21-99 All industrial installations (excl. combustion)` appear in any column.\n",
    "* Save in a new DataFrame all rows where `year` column >= 2010 and <= 2018.\n",
    "* Calculate in the new DataFrame how much emissions there have been in total each year (add together the values of the column `value`, which are grouped according to the values of the column `year`).\n",
    "* In the new column `change in percent`, calculate how much the emissions changed in percentage from the previous year. Round percentage changes to one decimal place.\n",
    "* Add a new column `cumulative sum` to the `DataFrame`, where the sum of emissions from 2010 to 2018 is calculated cumulatively. Note! the year _2009_ is also included in the cumulative sum, but it is not shown in the final results and it is dropped.\n",
    "* Set the DataFrame `index` to column `year`.\n",
    "* Return all rows in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dbb59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:33:41.333775Z",
     "start_time": "2025-02-05T17:33:41.318012Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                emissions    change in percent       cumulative sum\n",
      "year                                                               \n",
      "2010     4,728,330,103.00               -17.10    10,435,319,082.00\n",
      "2011     6,207,011,700.00                31.30    16,642,330,782.00\n",
      "2012     6,501,090,085.00                 4.70    23,143,420,867.00\n",
      "2013     3,160,894,807.00               -51.40    26,304,315,674.00\n",
      "2014     2,897,831,041.00                -8.30    29,202,146,715.00\n",
      "2015     2,254,673,985.00               -22.20    31,456,820,700.00\n",
      "2016     2,815,203,698.00                24.90    34,272,024,398.00\n",
      "2017     2,478,217,980.00               -12.00    36,750,242,378.00\n",
      "2018     2,685,203,623.00                 8.40    39,435,446,001.00\n",
      "Result was OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "correct_03_05 = pd.DataFrame({'emissions': {2010: 4728330103.0, 2011: 6207011700.0, 2012: 6501090085.0,\n",
    "                                            2013: 3160894807.0, 2014: 2897831041.0, 2015: 2254673985.0,\n",
    "                                            2016: 2815203698.0, 2017: 2478217980.0, 2018: 2685203623.0},\n",
    "                              'change in percent': {2010: -17.1, 2011: 31.3, 2012: 4.7, 2013: -51.4, 2014: -8.3,\n",
    "                                                    2015: -22.2, 2016: 24.9, 2017: -12.0, 2018: 8.4},\n",
    "                              'cumulative sum': {2010: 10435319082.0, 2011: 16642330782.0, 2012: 23143420867.0,\n",
    "                                                 2013: 26304315674.0, 2014: 29202146715.0, 2015: 31456820700.0,\n",
    "                                                 2016: 34272024398.0, 2017: 36750242378.0, 2018: 39435446001.0}})\n",
    "\n",
    "correct_03_05.index = correct_03_05.index.astype('int32')\n",
    "correct_03_05.index.name = \"year\"\n",
    "\n",
    "\n",
    "\n",
    "def emissions_per_year(url_src):\n",
    "    with open(url_src, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    headers = lines[0].strip().strip('\"').split('\\t')\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        clean_line = line.strip().strip('\"')\n",
    "        values = clean_line.split('\\t')\n",
    "        data.append(values)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    df = df[['country_code', 'main activity sector name', 'value', 'year']]\n",
    "    df.rename(columns={'main activity sector name': 'sector'}, inplace=True)\n",
    "    \n",
    "    df = df[~df['sector'].str.contains('20-99 All stationary installations|21-99 All industrial installations', regex=True)]\n",
    "    \n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "    df.dropna(subset=['year'], inplace=True)\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "    df.dropna(subset=['value'], inplace=True)\n",
    "    \n",
    "    df_full = df[(df['year'] >= 2009) & (df['year'] <= 2018)]\n",
    "    \n",
    "    yearly_emissions_all = df_full.groupby('year')['value'].sum().reset_index()\n",
    "    yearly_emissions_all.rename(columns={'value': 'emissions'}, inplace=True)\n",
    "    \n",
    "    # Muunna emissions float-tyypiksi\n",
    "    yearly_emissions_all['emissions'] = yearly_emissions_all['emissions'].astype('float64')\n",
    "    \n",
    "    yearly_emissions_all['change in percent'] = yearly_emissions_all['emissions'].pct_change() * 100\n",
    "    yearly_emissions_all['change in percent'] = yearly_emissions_all['change in percent'].round(1)\n",
    "    yearly_emissions_all['cumulative sum'] = yearly_emissions_all['emissions'].cumsum()\n",
    "    \n",
    "    result = yearly_emissions_all[(yearly_emissions_all['year'] >= 2010) & (yearly_emissions_all['year'] <= 2018)]\n",
    "    result.set_index('year', inplace=True)\n",
    "    \n",
    "    result.index = result.index.astype('int32')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# The Test Program includes automatic checking of the answer\n",
    "url_src = r\"C:\\Users\\jmhel\\OneDrive\\Työpöytä\\JAMK\\DA & Visualization\\emissions.csv\"\n",
    "res = emissions_per_year(url_src)\n",
    "\n",
    "try:\n",
    "    print(res.to_string())\n",
    "    pd.testing.assert_frame_equal(res, correct_03_05, check_dtype=True)\n",
    "    print(f'Result was OK')\n",
    "except AssertionError as err_msg:\n",
    "    print(err_msg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
